# AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ Web ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æŠ€è¡“å®šç¾©æ›¸  
**ï¼ˆMCP ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç‰ˆ / ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ Version 3.0ï¼‰**

æœ€çµ‚æ›´æ–°æ—¥: 2025-06-02  

---

## 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

### 1.1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
**Extend Your Memory**

### 1.2. ç›®çš„
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒéå»ã«é–²è¦§ãƒ»ä¿å­˜ã—ãŸ **Google Drive ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ–ãƒ©ã‚¦ã‚¶å±¥æ­´ãƒ»Web ãƒšãƒ¼ã‚¸** ã‚’ä¸€æ‹¬æ¤œç´¢ã—ã€å¼•ç”¨ä»˜ããƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹å€‹äººå‘ã‘ AI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### 1.3. ã‚³ã‚¢ãƒãƒªãƒ¥ãƒ¼
- ã€Œã“ã‚Œã©ã“ã‹ã§è¦‹ãŸæ°—ãŒã™ã‚‹ãªãï¼ï¼ï¼ã€ã‚’è§£æ¶ˆ
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒéå»ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸè¤‡æ•°ã®æƒ…å ±æºã‹ã‚‰è‡ªå‹•çš„ã«æƒ…å ±ã‚’çµ±åˆ
- é©åˆ‡ãªå¼•ç”¨ã‚’å«ã‚€æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
- æ‰‹å‹•ã§ã®æƒ…å ±åé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã«ã‹ã‹ã‚‹æ™‚é–“ã‚’å¤§å¹…ã«å‰Šæ¸›

---

## 2. ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆMCPç‰ˆï¼‰

```mermaid
graph TD
    subgraph Frontend
        User[ğŸ§‘â€ğŸ’» ãƒ¦ãƒ¼ã‚¶ãƒ¼<br>Next.js 14] -->|REST/WS| API
    end

    subgraph Backend
        API[FastAPI] -->|1. ãƒ¦ãƒ¼ã‚¶ã‚¯ã‚¨ãƒª| LLM1[LLM<br>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ]
        LLM1 -->|2. æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰| MCP[MCP Server]
        
        subgraph "MCP (Model Context Protocol)"
            MCP --> GDriveTool[Google Drive Tool]
            MCP --> ChromeTool[Chrome History Tool]
            MCP --> OCRTool[Mistral OCR Tool]
            
            GDriveTool -->|æ¤œç´¢| GDrive[Google Drive API]
            ChromeTool -->|æ¤œç´¢| Chrome[Chrome History API]
            OCRTool -->|PDFâ†’MDå¤‰æ›| MistralOCR[Mistral OCR API]
        end
        
        MCP -->|3. ã‚½ãƒ¼ã‚¹è¿”å´| VectorProcessor[Vector DBå‡¦ç†]
        VectorProcessor -->|4. ãƒ™ã‚¯ãƒˆãƒ«åŒ–| VectorDB[(PostgreSQL + pgvector)]
        
        VectorDB -->|5. RAGã‚¯ã‚¨ãƒª| LLM2[LLM<br>RAGæ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ]
        LLM2 -->|6. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢| RAG[RAG Pipeline]
        RAG -->|7. æƒ…å ±å–å¾—| LLM3[LLM<br>ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ]
        LLM3 -->|8. ãƒ¬ãƒãƒ¼ãƒˆ+å¼•ç”¨| API
    end
```

## 3. å‡¦ç†ãƒ•ãƒ­ãƒ¼è©³ç´°

### 3.1. å…¨ä½“ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant U as ãƒ¦ãƒ¼ã‚¶ãƒ¼
    participant F as Frontend
    participant B as Backend API
    participant L as LLM
    participant M as MCP Server
    participant V as Vector DB
    participant R as RAG

    U->>F: ã‚¯ã‚¨ãƒªå…¥åŠ›
    F->>B: POST /chat/message
    
    Note over B,L: 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º
    B->>L: ãƒ¦ãƒ¼ã‚¶ã‚¯ã‚¨ãƒªã‚’é€ä¿¡
    L->>L: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
    L-->>B: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
    
    Note over B,M: 2-3. MCPæ¤œç´¢ãƒ•ã‚§ãƒ¼ã‚º
    B->>M: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é€ä¿¡
    M->>M: Google Driveæ¤œç´¢
    M->>M: Chromeå±¥æ­´æ¤œç´¢
    M->>M: PDFâ†’MDå¤‰æ›ï¼ˆå¿…è¦æ™‚ï¼‰
    M-->>B: ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿”å´
    
    Note over B,V: 4. ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ•ã‚§ãƒ¼ã‚º
    B->>V: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    B->>V: Embeddingã¨ã‚¹ãƒˆã‚¢
    
    Note over B,R: 5-6. RAGæ¤œç´¢ãƒ•ã‚§ãƒ¼ã‚º
    B->>L: RAGæ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆä¾é ¼
    L-->>B: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚¯ã‚¨ãƒª
    B->>R: RAGæ¤œç´¢å®Ÿè¡Œ
    R-->>B: é–¢é€£æƒ…å ±å–å¾—
    
    Note over B,L: 7. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º
    B->>L: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‹æƒ…å ±ã‚’é€ä¿¡
    L->>L: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    L-->>B: æ§‹é€ åŒ–ãƒ¬ãƒãƒ¼ãƒˆ
    
    Note over B,F: 8. çµæœè¿”å´
    B->>F: ãƒ¬ãƒãƒ¼ãƒˆï¼‹å¼•ç”¨æƒ…å ±
    F->>U: UIã«è¡¨ç¤º
```

### 3.2. MCPï¼ˆModel Context Protocolï¼‰ã®å½¹å‰²

MCPã¯ã€LLMã¨ã®å¯¾è©±ã‚’é€šã˜ã¦å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ä»²ä»‹ã™ã‚‹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ï¼š

#### 3.2.1. Google Drive Tool
```python
@mcp_tool
async def search_google_drive(
    keywords: List[str],
    file_types: Optional[List[str]] = None,
    folder_id: Optional[str] = "root"
) -> List[Document]:
    """Google Driveã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    # Drive API ã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å®Ÿè£…
    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•çš„ã«OCR Toolã«è»¢é€
```

#### 3.2.2. Chrome History Tool
```python
@mcp_tool
async def search_chrome_history(
    keywords: List[str],
    date_range: Optional[DateRange] = None
) -> List[HistoryItem]:
    """Chromeå±¥æ­´ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ¤œç´¢"""
    # Chrome History APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å®Ÿè£…
```

#### 3.2.3. Mistral OCR Tool
```python
@mcp_tool
async def ocr_pdf_to_markdown(
    file_path: str,
    language: str = "ja"
) -> str:
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’Mistral OCRã§Markdownå¤‰æ›"""
    # Mistral OCR APIã‚’ä½¿ç”¨ã—ãŸå¤‰æ›å®Ÿè£…
```

## 4. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ï¼ˆMCPå¯¾å¿œç‰ˆï¼‰

| å±¤ | ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ã‚µãƒ¼ãƒ“ã‚¹ | å‚™è€ƒ |
|----|--------------------|------|
| **LLM** | Gemini 2.5 flash | ãƒ¡ã‚¤ãƒ³LLM |
| **MCPå®Ÿè£…** | `langchain-mcp-adapters` | LangChainå…¬å¼MCPçµ±åˆ |
| **MCPãƒ„ãƒ¼ãƒ«** | ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£… | Google Drive, Chrome, OCR |
| **LangChain** | `langchain==0.3.*` | RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç”¨ |
| **Vector DB** | `FAISS` | é«˜é€Ÿãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ |
| **Embedding** | `models/embedding-004` (Google) | æœ€æ–°ã®å¤šè¨€èªå¯¾å¿œ |
| **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰** | FastAPI + Pydantic v2 | |
| **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰** | Next.js 14 (App Router) | |

## 5. MCP ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…

### 5.1. LangChain MCP Adapter ã«ã‚ˆã‚‹å®Ÿè£…

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import load_mcp_tools
from mcp.server.fastmcp import FastMCP

# MCPã‚µãƒ¼ãƒãƒ¼ã®å®šç¾©
class ExtendMemoryMCPServer:
    """Extend Your Memoryç”¨ã®MCPã‚µãƒ¼ãƒãƒ¼å®Ÿè£…"""
    
    def __init__(self):
        self.mcp = FastMCP("ExtendMemory")
        self.register_tools()
    
    def register_tools(self):
        """åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’ç™»éŒ²"""
        
        @self.mcp.tool()
        async def search_google_drive(
            keywords: List[str],
            file_types: Optional[List[str]] = None,
            folder_id: Optional[str] = "root"
        ) -> List[Dict[str, Any]]:
            """Google Driveã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
            # Google Drive APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å®Ÿè£…
            from langchain_google_community import GoogleDriveLoader
            
            loader = GoogleDriveLoader(
                folder_id=folder_id,
                file_types=file_types or ["document", "sheet", "pdf"],
                recursive=True,
                num_results=50,
                load_auth=True  # æ¨©é™æƒ…å ±ã‚‚èª­ã¿è¾¼ã¿
            )
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            documents = []
            for doc in loader.load():
                if any(keyword.lower() in doc.page_content.lower() for keyword in keywords):
                    documents.append({
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "file_id": doc.metadata.get("id"),
                        "title": doc.metadata.get("title"),
                        "mime_type": doc.metadata.get("mimeType")
                    })
            
            return documents
        
        @self.mcp.tool()
        async def search_chrome_history(
            keywords: List[str],
            days: int = 30
        ) -> List[Dict[str, Any]]:
            """Chromeå±¥æ­´ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ¤œç´¢"""
            # AsyncChromiumLoaderã‚’ä½¿ç”¨ã—ãŸãƒ–ãƒ©ã‚¦ã‚¶å±¥æ­´å–å¾—
            from langchain_community.document_loaders import AsyncChromiumLoader
            
            # Chromeå±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼è¨±å¯å¿…è¦ï¼‰
            history_items = []
            # å®Ÿè£…è©³ç´°...
            
            return history_items
        
        @self.mcp.tool()
        async def ocr_pdf_to_markdown(
            file_content: bytes,
            file_name: str
        ) -> str:
            """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’Mistral OCRã§Markdownå¤‰æ›"""
            from mistralai import Mistral
            
            client = Mistral(api_key=os.getenv("MISTRAL_API_KEY"))
            
            # Mistral OCR APIã‚’ä½¿ç”¨
            response = client.ocr.process(
                file_content=file_content,
                file_name=file_name,
                format="markdown"
            )
            
            return response.text

### 5.2. LangChainçµ±åˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
# MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
mcp_client = MultiServerMCPClient({
    "extend_memory": {
        "command": "python",
        "args": ["./mcp_server.py"],
        "transport": "stdio"
    }
})

# LangChainãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ä½¿ç”¨
tools = await mcp_client.get_tools()
```

## 6. RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…ï¼ˆMCPçµ±åˆç‰ˆï¼‰

```python
from langchain.chains import create_retrieval_chain
from langchain.schema.runnable import RunnableParallel, RunnablePassthrough
from langchain.prompts import PromptTemplate
from langchain.chat_models import init_chat_model
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter
from langchain_mcp_adapters.client import MultiServerMCPClient

# 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆãƒã‚§ãƒ¼ãƒ³
keyword_prompt = PromptTemplate(
    template="""ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•: {question}

ã“ã®è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
1. è³ªå•ã®æ ¸å¿ƒçš„ãªãƒˆãƒ”ãƒƒã‚¯
2. é–¢é€£ã™ã‚‹æŠ€è¡“ç”¨èªï¼ˆæ—¥æœ¬èªãƒ»è‹±èªä¸¡æ–¹ï¼‰
3. é¡ä¼¼æ¦‚å¿µã‚„åŒç¾©èª
4. æ™‚æœŸã‚„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«é–¢ã™ã‚‹æƒ…å ±

JSONå½¢å¼ã§5-10å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›å½¢å¼: {"keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "keyword2", ...]}"""
)

model = init_chat_model("gemini-2.5-flash", model_provider="google_genai")
keyword_chain = keyword_prompt | model

# 2. MCPçµ±åˆè¨­å®š
mcp_client = MultiServerMCPClient({
    "extend_memory": {
        "command": "python",
        "args": ["./mcp_server.py"],
        "transport": "stdio"
    }
})

async def search_with_mcp(keywords: List[str]) -> List[Document]:
    """MCPã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢"""
    tools = await mcp_client.get_tools()
    
    # search_google_driveãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
    gdrive_tool = next(t for t in tools if t.name == "search_google_drive")
    gdrive_results = await gdrive_tool.ainvoke({"keywords": keywords})
    
    # search_chrome_historyãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
    chrome_tool = next(t for t in tools if t.name == "search_chrome_history")
    chrome_results = await chrome_tool.ainvoke({"keywords": keywords})
    
    # çµæœã‚’çµ±åˆ
    all_documents = gdrive_results + chrome_results
    
    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®OCRå‡¦ç†
    ocr_tool = next(t for t in tools if t.name == "ocr_pdf_to_markdown")
    for doc in all_documents:
        if doc.metadata.get("mime_type") == "application/pdf":
            ocr_result = await ocr_tool.ainvoke({
                "file_content": doc.page_content,
                "file_name": doc.metadata.get("title")
            })
            doc.page_content = ocr_result
            doc.metadata["ocr_processed"] = True
    
    return all_documents

# 3. ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²è¨­å®š
def split_documents(documents: List[Document]) -> List[Document]:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’é©åˆ‡ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
    all_splits = []
    
    for doc in documents:
        if doc.metadata.get("ocr_processed") or ".md" in doc.metadata.get("title", ""):
            # Markdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å ´åˆ
            headers_to_split_on = [
                ("#", "Header 1"),
                ("##", "Header 2"),
                ("###", "Header 3")
            ]
            markdown_splitter = MarkdownHeaderTextSplitter(
                headers_to_split_on=headers_to_split_on,
                strip_headers=False
            )
            md_splits = markdown_splitter.split_text(doc.page_content)
            
            # ã•ã‚‰ã«æ–‡å­—æ•°ã§åˆ†å‰²
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            for split in md_splits:
                chunks = text_splitter.split_documents([split])
                all_splits.extend(chunks)
        else:
            # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                separators=["\n\n", "\n", "ã€‚", ".", " ", ""]
            )
            chunks = text_splitter.split_documents([doc])
            all_splits.extend(chunks)
    
    return all_splits

# 4. ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ã‚¹ãƒˆã‚¢
embedding = GoogleGenerativeAIEmbeddings(
    model="models/embedding-004",
    google_api_key=os.getenv("GOOGLE_API_KEY")
)

# FAISSãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®åˆæœŸåŒ–
vector_store = None

async def process_and_store_documents(documents: List[Document]) -> FAISS:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«ä¿å­˜"""
    global vector_store
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²
    splits = split_documents(documents)
    
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ã‚¹ãƒˆã‚¢
    if vector_store is None:
        vector_store = FAISS.from_documents(
            documents=splits,
            embedding=embedding
        )
    else:
        vector_store.add_documents(splits)
    
    return vector_store

# 5. RAGæ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ
rag_query_prompt = PromptTemplate(
    template="""å…ƒã®è³ªå•: {original_question}
å–å¾—ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„: {doc_summary}

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®è¦³ç‚¹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. è³ªå•ã®æœ¬è³ªçš„ãªæ„å›³
2. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæ–°ã—ã„è¦–ç‚¹
3. é–¢é€£ã™ã‚‹æ¦‚å¿µã®æ·±å €ã‚Š

5-10å€‹ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›å½¢å¼: {"queries": ["ã‚¯ã‚¨ãƒª1", "ã‚¯ã‚¨ãƒª2", ...]}"""
)

rag_query_chain = rag_query_prompt | model

# 6. å®Œå…¨ãªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
async def full_rag_pipeline(user_query: str) -> Dict[str, Any]:
    """å®Œå…¨ãªRAGå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
    keywords_response = await keyword_chain.ainvoke({"question": user_query})
    keywords = json.loads(keywords_response.content)
    
    # ã‚¹ãƒ†ãƒƒãƒ—2-3: MCPæ¤œç´¢
    documents = await search_with_mcp(keywords["keywords"])
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ã‚¹ãƒˆã‚¢
    vector_store = await process_and_store_documents(documents)
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„ç”Ÿæˆ
    doc_summary = "\n".join([doc.page_content[:200] for doc in documents[:5]])
    
    # ã‚¹ãƒ†ãƒƒãƒ—5: RAGæ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ
    rag_queries_response = await rag_query_chain.ainvoke({
        "original_question": user_query,
        "doc_summary": doc_summary
    })
    rag_queries = json.loads(rag_queries_response.content)
    
    # ã‚¹ãƒ†ãƒƒãƒ—6: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ï¼ˆFAISSä½¿ç”¨ï¼‰
    relevant_docs = []
    for query in rag_queries["queries"]:
        # FAISSã®MMRï¼ˆMaximal Marginal Relevanceï¼‰æ¤œç´¢ã‚’ä½¿ç”¨
        docs = vector_store.max_marginal_relevance_search(
            query, 
            k=3,
            fetch_k=10,
            lambda_mult=0.5
        )
        relevant_docs.extend(docs)
    
    # é‡è¤‡é™¤å»
    unique_docs = {doc.metadata.get("file_id", doc.page_content[:50]): doc 
                   for doc in relevant_docs}.values()
    
    # ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_prompt = PromptTemplate(
        template="""è³ªå•: {question}

ä»¥ä¸‹ã®æƒ…å ±æºã‚’åŸºã«ã€æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{context}

ãƒ¬ãƒãƒ¼ãƒˆã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. è¦ç´„ï¼ˆExecutive Summaryï¼‰
2. è©³ç´°ãªåˆ†æ
3. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ
4. å¼•ç”¨æƒ…å ±ï¼ˆå„æƒ…å ±ã«ã¯å¿…ãšå‡ºå…¸ã‚’æ˜è¨˜ï¼‰

ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    context = "\n---\n".join([
        f"å‡ºå…¸: {doc.metadata}\nå†…å®¹: {doc.page_content}"
        for doc in list(unique_docs)[:10]  # æœ€å¤§10ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¾ã§
    ])
    
    report_chain = report_prompt | model
    report = await report_chain.ainvoke({
        "question": user_query,
        "context": context
    })
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    vector_store.save_local("./vector_store_cache")
    
    return {
        "report": report.content,
        "sources": [doc.metadata for doc in unique_docs],
        "keywords_used": keywords["keywords"],
        "rag_queries": rag_queries["queries"],
        "total_documents": len(documents),
        "relevant_documents": len(list(unique_docs))
    }
```

## 7. APIè¨­è¨ˆï¼ˆMCPå¯¾å¿œç‰ˆï¼‰

### 7.1. WebSocket ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæ¤œç´¢ãƒ—ãƒ­ã‚»ã‚¹å¯è¦–åŒ–ï¼‰

```python
# ã‚¹ãƒ†ãƒƒãƒ—1: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
{
    "event": "search_progress",
    "data": {
        "step": 1,
        "stage": "keyword_generation",
        "message": "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆä¸­...",
        "details": {
            "query": "LLMã®æœ€æ–°æŠ€è¡“å‹•å‘ã«ã¤ã„ã¦"
        }
    }
}

# ã‚¹ãƒ†ãƒƒãƒ—2-3: MCPæ¤œç´¢
{
    "event": "search_progress", 
    "data": {
        "step": 2,
        "stage": "mcp_search",
        "message": "MCPã‚µãƒ¼ãƒãƒ¼ã§ã‚½ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­...",
        "details": {
            "keywords": ["LLM", "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«", "Transformer"],
            "searching": ["google_drive", "chrome_history"]
        }
    }
}

# ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ™ã‚¯ãƒˆãƒ«åŒ–
{
    "event": "search_progress",
    "data": {
        "step": 4,
        "stage": "vectorization",
        "message": "å–å¾—ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...",
        "details": {
            "total_documents": 25,
            "processed": 15,
            "sources": {
                "google_drive": 12,
                "chrome_history": 13
            }
        }
    }
}

# ã‚¹ãƒ†ãƒƒãƒ—5-6: RAGæ¤œç´¢
{
    "event": "search_progress",
    "data": {
        "step": 5,
        "stage": "rag_search",
        "message": "ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’å®Ÿè¡Œä¸­...",
        "details": {
            "rag_queries": [
                "æœ€æ–°ã®LLMã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãã®ç‰¹å¾´",
                "Transformerãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡åŒ–æ‰‹æ³•",
                "æ—¥æœ¬èªLLMã®é–‹ç™ºå‹•å‘"
            ]
        }
    }
}

# ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
{
    "event": "search_progress",
    "data": {
        "step": 7,
        "stage": "report_generation",
        "message": "ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...",
        "details": {
            "relevant_sources": 8,
            "citations_count": 15
        }
    }
}
```

## 8. ç’°å¢ƒæ§‹ç¯‰ã¨ãƒ‡ãƒ—ãƒ­ã‚¤

### 8.1. Dockeræ§‹æˆ

```yaml
# docker-compose.yml
version: '3.9'

services:
  # MCPã‚µãƒ¼ãƒãƒ¼
  mcp-server:
    build: ./mcp-server
    environment:
      - GOOGLE_DRIVE_API_KEY=${GOOGLE_DRIVE_API_KEY}
      - CHROME_API_KEY=${CHROME_API_KEY}
      - MISTRAL_OCR_API_KEY=${MISTRAL_OCR_API_KEY}
    ports:
      - "8501:8501"
    volumes:
      - ./mcp-tools:/app/tools
  
  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API
  backend:
    build: ./backend
    environment:
      - MCP_SERVER_URL=http://mcp-server:8501
    ports:
      - "8000:8000"
    depends_on:
      - mcp-server
  
  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
```

## 9. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼

### 9.1. API ã‚­ãƒ¼ç®¡ç†
- å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†ã®APIã‚­ãƒ¼ã‚’è¨­å®š
- ã‚­ãƒ¼ã¯æš—å·åŒ–ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
- ã‚µãƒ¼ãƒãƒ¼å´ã§ã¯ä¸€æ™‚çš„ã«ãƒ¡ãƒ¢ãƒªä¸Šã§ã®ã¿ä¿æŒ

### 9.2. ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼
- Chromeå±¥æ­´ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã¯æ˜ç¤ºçš„ãªè¨±å¯ãŒå¿…è¦
- Google Driveã®ã‚¢ã‚¯ã‚»ã‚¹ã‚¹ã‚³ãƒ¼ãƒ—ã¯æœ€å°é™ã«è¨­å®š
- ãƒ™ã‚¯ãƒˆãƒ«DBã®ãƒ‡ãƒ¼ã‚¿ã¯å®šæœŸçš„ã«å‰Šé™¤å¯èƒ½

## 10. ä»Šå¾Œã®æ‹¡å¼µè¨ˆç”»

1. **MCPãƒ„ãƒ¼ãƒ«ã®è¿½åŠ **
   - Slackæ¤œç´¢ãƒ„ãƒ¼ãƒ«
   - Notionæ¤œç´¢ãƒ„ãƒ¼ãƒ«
   - ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ„ãƒ¼ãƒ«

2. **LLMã®æœ€é©åŒ–**
   - ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¿½åŠ 
   - ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹æ¤œç´¢ç²¾åº¦å‘ä¸Š

3. **UI/UXã®æ”¹å–„**
   - æ¤œç´¢çµæœã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªå¯è¦–åŒ–
   - ãƒ¬ãƒãƒ¼ãƒˆã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å…±åŒç·¨é›†

